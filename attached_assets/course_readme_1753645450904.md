# ğŸ¨ Real Estate AI Stack

This project is a locally-run AI-powered assistant for analyzing real estate course materials. It supports ingestion of multiple formats (PDF, DOCX, PPTX), indexes courses using LlamaIndex, and runs a Streamlit-based UI for querying course content using Mistral 7B (local GGUF).

---

## âœ… Features

- Multi-course document indexing with LlamaIndex
- Local LLM inference via `llama-cpp-python` using GGUF models
- Streamlit UI for querying indexed courses
- Automatic re-indexing, syllabus-weighted prioritization (if enabled)
- Support for PDFs, DOCXs, PPTXs

---

## ğŸ§° System Requirements

- **OS**: Windows 10/11 or Linux/macOS
- **Python**: 3.12 (installed via [Python.org](https://www.python.org/downloads/))
- **RAM**: 16GB+ recommended
- **GPU**: Optional, supports CPU-only mode

---

## ğŸ“¦ Installation Instructions

### 1. Clone or unzip project folder

```bash
git clone https://github.com/YOUR_USERNAME/real_estate_ai_stack.git
cd real_estate_ai_stack
```

Or unzip `real_estate_ai_stack_final_flat.zip` to any folder.

---

### 2. Create a virtual environment (optional but recommended)

```bash
python -m venv venv
venv\Scripts\activate   # On Windows
source venv/bin/activate  # On Linux/macOS
```

---

### 3. Install Python dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

âš ï¸ If `llama-cpp-python` fails to build:

- Install Visual Studio Build Tools (C++) from [https://visualstudio.microsoft.com/visual-cpp-build-tools/](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
- Or use prebuilt wheel (if available for your CPU)

---

## ğŸ§  Model Setup (Mistral 7B GGUF)

Place the model file here:

```
models/
â””â”€â”€ mistral-7b-instruct-v0.1.Q4_K_M.gguf
```

If missing, run:

```bash
python update_mistral_model.py
```

(This will download the model from HuggingFace or use local cache.)

---

## ğŸ“ File Structure

```
real_estate_ai_stack/
ï¹£
ğŸ” app_multi_course.py              # Main Streamlit entrypoint
ğŸ” start_app.py                     # Shortcut launcher
ğŸ” mistral_query_engine.py          # Local LLM config + service context
ğŸ” requirements.txt
ğŸ” update_mistral_model.py
ğŸ” manual_index_all_courses.py
ğŸ—‚ï¸ models/
â”œâ”€â”€ mistral-7b-instruct-v0.1.Q4_K_M.gguf
ğŸ—‚ï¸ indexed_courses/
â”œâ”€â”€ [course folders...]
ğŸ—‚ï¸ raw_docs/
â””â”€â”€ [your PDFs, DOCXs, PPTXs]
ğŸ” README.md
```

---

## ğŸš€ Run the App

```bash
python start_app.py
```

Visit `http://localhost:8501` in your browser.

---

## ğŸ’  Troubleshooting

### ğŸ”„ Missing `manual_index_all_courses.py`

Copy from backup or download again from the zip.

### âŒ `ImportError` with `llama_index`

Use `llama-index==0.10.20`. Avoid 0.9.x or early 0.10.x.

```bash
pip install "llama-index==0.10.20"
```

### ğŸ§± `llama-cpp-python` build failed

Install with:

```bash
pip install llama-cpp-python --prefer-binary --force-reinstall
```

Or skip local model by using OpenAI API temporarily.

---

## ğŸ““ Tips

- All course documents should go in `raw_docs/`
- Indexed data is cached in `indexed_courses/`
- For new courses: delete and re-index via `manual_index_all_courses.py`
- Update `.env` for custom API keys if using OpenAI

---

## ğŸ” Optional: Secure Deployment

To protect localhost from public access:

- Use firewall to block external port 8501
- Or use reverse proxy (nginx) with basic auth

---

## ğŸ“¦ Zip and Backup

To create a fully flattened backup:

```bash
python create_backup_zip.py  # Optional helper script
```

This includes all Python scripts, models, and local indexes.

---

## ğŸ¤ Credits

- Built using [LlamaIndex](https://github.com/jerryjliu/llama_index)
- Local inference via [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
- UI via [Streamlit](https://streamlit.io/)

